\chapter{总结与展望}
\label{cha:summary}
\section{工作总结}

时间序列数据遍布金融、互联网、制造等各个行业，越来越多的机器学习算法应用于时间序列数据帮助进行分析和决策，使人们意识到了时间序列的价值，开始投入精力研究时间序列数据挖掘。Shapelet是具有一种具有很好分类能力的子序列，能够对于没有类标的数据进行分类。但是Shapelet的发现过程是很消耗时间和资源的过程。为了提高获得Shapelet的速度，本文提出了一种基于DTW距离测度的Shapelet并行方法，主要工作分为以下几点：

1.提出了一种计算Shapelet的计算框架，根据数据集的不同（实际根据是不同都会根据内存的消耗情况以及$N,L$的大小）来确定合适的方法，能够对于较大的数据集进行处理。并且可以根据$w$参数来选择子序列间相似度计算的弯曲匹配程度，在$w=0\to |S|$区间内选择使准确最高的候选序列。

2.在距离计算阶段，根据$w$的不同，分别设计了w>0距离计算方法和w=0距离计算方法，两者都利用了不同候选序列和时间序列的距离之间的关系，来避免重复性计算降低时间复杂度。在设计并行算法时，将并行算法和CUDA优化技术结合使在有限的图形处理器资源上进行更多的计算，这些优化技术包括线程通信、合并内存访问、Warp分歧、存储体冲突、矩阵转置等。

3.在计算最佳分割点阶段，使用一种启发式计算最佳分割点+随机排列的方法在保证准确率不降的基础上来减少计算最佳分割点需要的时间，其中，启发式算法用来降低时间复杂度，随机排列使启发式获得分割点趋近最优值。

4.在w>0距离计算阶段、w=0距离计算级阶段、最佳分割点计算阶段，会估计不同数据集即不同$w,N,L$参数下每个$Block$中共享内存和寄存器的使用情况，然后会根据不同资源使用情况调节$Block$和$Grid$参数，避免单个Warp占用资源太多，而影响SM上同时执行的Warp个数，这样可以使有限的资源上进行更多的计算。

5.最后对于算法在多个数据集上进行了验证，和深度学习进行了准确率方面的比较，和已有优化算法进行比较效率方面的比较。对于距离计算阶段各个CUDA优化技术和算法结合对于优化加速的影响进行了验证。最佳分割点计算时分别使用启发式算法和传统算法在准确率和性能方面进行了比较。


\section{对未来工作的展望}

本文中我们提出的基于DTW距离测度的Shapelet并行方法虽然在性能优化上解决了一定的问题，但是整个算法还是存在很多优化的空间，具有如下面几个方面：

1.本文中对于距离的计算$Dist(A,B)$是按照时间序列内部的实际值计算的，还可以对$A,B$进行标准化之后再进行计算距离$Dist(zscore(A),zscore(B))$，来进一步提高准确率指标。但是因为本算法内部使用了重用策略，如果加入标准化之后仍然想使用重用策略，这里就重新考虑标准化之后距离之间的转化。对于$w=0$时，需要计算$Dist(zscore(T_{i,s+1}^{len}),zscore(T_{j,p+1}^{len}))$和$Dist(zscore(T_{i,s}^{len}),zscore(T_{j,p}^{len}))$两者之间关系；而对于$w>0$情况来说,就需要计算$DTW(zscore(A_{1:m}),zscore(B_{1:m}),w)$ 和 $DTW(zscore(A_{1:m+1}),zscore(B_{1:m+1}),w)$两者之间的关系。

2.对于定制化需求的矩阵转置部分，还存在可以优化的空间，目前的定制化矩阵转置算法每次从$block$产生的矩阵读取一行数据，当数据集中时间序列长度$L$较小时没有问题，但当$L$较大时，需要较多的共享内存空间，使得每个SM中同时执行的Warp个数减少从而影响执行效率。对于$L$较大占用较大资源的问题，可以通过将每次读取的一行进行分段读取，前提是满足合并内存访问。

3.文中提到时间序列数据必须考虑其长尾分布，本文使用数据集的最大的正负样本比例为$1:3$。应该在正负样本比例更大的数据集中进行试验，以保证Shapelet方法对于正负样本不敏感并且能够对长尾时间序列进行正确分类。

4.对于延时隐藏还可以继续改进，目前显示$block$和$grid$的参数都是经过简单比较获得的，不能确定目前的参数是否最优。可以加入占有率的计算和资源分配计算确保目前是能够最大限度利用GPU资源。


